{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTY:\n",
    "\n",
    "# Of distribution:\n",
    "normaltest(a[, axis, nan_policy])   # - sample dist is normal,\n",
    "skewtest(a[, axis, nan_policy])     # - is ds skew normal,\n",
    "kurtosistest(a[, axis, nan_policy]) # - ds kurt is normal.\n",
    "\n",
    "\n",
    "# Performs a 1-way ANOVA.\n",
    "f_oneway(*args)\n",
    "\n",
    "pearsonr(x, y) # correlation coefficient and the p-value for testing non-correlation.\n",
    "spearmanr(a[, b, axis, nan_policy]) # rank-order correlation coefficient and the p-value to test for non-correlation.\n",
    "\n",
    "\n",
    "pointbiserialr(x, y) # point biserial correlation coefficient and its p-value.\n",
    "\n",
    "\n",
    "kendalltau(x, y[, initial_lexsort, nan_policy]) # a correlation measure for ordinal data.\n",
    "# Compute a weighted version of Kendall’s .\n",
    "weightedtau(x, y[, rank, weigher, additive])\n",
    "# Calculate a linear least-squares regression for two sets of measurements.\n",
    "linregress(x[, y])\n",
    "# Computes the Theil-Sen estimator for a set of points (x, y).\n",
    "theilslopes(y[, x, alpha])\n",
    "\n",
    "\n",
    "# Calculate the T-test for the mean of ONE group of scores.\n",
    "ttest_1samp(a, popmean[, axis, nan_policy])\n",
    "# Calculate the T-test for the means of two independent samples of scores.\n",
    "ttest_ind(a, b[, axis, equal_var, nan_policy])\n",
    "# T-test for means of two independent samples from descriptive statistics.\n",
    "ttest_ind_from_stats(mean1, std1, nobs1, …)\n",
    "# Calculate the T-test on TWO RELATED samples of scores, a and b.\n",
    "ttest_rel(a, b[, axis, nan_policy])\n",
    "# Perform the Kolmogorov-Smirnov test for goodness of fit.\n",
    "kstest(rvs, cdf[, args, N, alternative, mode])\n",
    "# Calculate a one-way chi square test.\n",
    "chisquare(f_obs[, f_exp, ddof, axis])\n",
    "# Cressie-Read power divergence statistic and goodness of fit test.\n",
    "power_divergence(f_obs[, f_exp, ddof, axis, …])\n",
    "# Compute the Kolmogorov-Smirnov statistic on 2 samples.\n",
    "ks_2samp(data1, data2)\n",
    "# Compute the Mann-Whitney rank test on samples x and y.\n",
    "mannwhitneyu(x, y[, use_continuity, alternative])\n",
    "# Tie correction factor for ties in the Mann-Whitney U and Kruskal-Wallis H tests.\n",
    "tiecorrect(rankvals)\n",
    "# Assign ranks to data, dealing with ties appropriately.\n",
    "rankdata(a[, method])\n",
    "# Compute the Wilcoxon rank-sum statistic for two samples.\n",
    "ranksums(x, y)\n",
    "# Calculate the Wilcoxon signed-rank test.\n",
    "wilcoxon(x[, y, zero_method, correction])\n",
    "# Compute the Kruskal-Wallis H-test for independent samples\n",
    "kruskal(*args, **kwargs)\n",
    "# Compute the Friedman test for repeated measurements\n",
    "friedmanchisquare(*args)\n",
    "# Methods for combining the p-values of independent tests bearing upon the same hypothesis.\n",
    "combine_pvalues(pvalues[, method, weights])\n",
    "# Perform the Jarque-Bera goodness of fit test on sample data.\n",
    "jarque_bera(x)\n",
    "\n",
    "# Perform the Ansari-Bradley test for equal scale parameters\n",
    "ansari(x, y)\n",
    "# Perform Bartlett’s test for equal variances\n",
    "bartlett(*args)\n",
    "# Perform Levene test for equal variances.\n",
    "levene(*args, **kwds)\n",
    "# Perform the Shapiro-Wilk test for normality.\n",
    "shapiro(x)\n",
    "# Anderson-Darling test for data coming from a particular distribution\n",
    "anderson(x[, dist])\n",
    "\n",
    "# The Anderson-Darling test for k-samples.\n",
    "anderson_ksamp(samples[, midrank])\n",
    "# Perform a test that the probability of success is p.\n",
    "binom_test(x[, n, p, alternative])\n",
    "# Perform Fligner-Killeen test for equality of variance.\n",
    "fligner(*args, **kwds)\n",
    "# Mood’s median test.\n",
    "median_test(*args, **kwds)\n",
    "# Perform Mood’s test for equal scale parameters.\n",
    "mood(x, y[, axis])\n",
    "\n",
    "# Chi-square test of independence of variables in a contingency table.\n",
    "chi2_contingency(observed[, correction, lambda_])\n",
    "# Performs a Fisher exact test on a 2x2 contingency table.\n",
    "fisher_exact(table[, alternative])\n",
    "# Plot-tests\n",
    "# ----------\n",
    "# Calculate the shape parameter that maximizes the PPCC\n",
    "ppcc_max(x[, brack, dist])\n",
    "# Calculate and optionally plot probability plot correlation coefficient.\n",
    "ppcc_plot(x, a, b[, dist, plot, N])\n",
    "# Calculate quantiles for a probability plot, and optionally show the plot.\n",
    "probplot(x[, sparams, dist, fit, plot, rvalue])\n",
    "# Compute parameters for a Box-Cox normality plot, optionally show it.\n",
    "boxcox_normplot(x, la, lb[, plot, N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical functions\n",
    "# ---------------------\n",
    "\n",
    "\n",
    "\n",
    "# Descriptive statistics\n",
    "# ----------------------\n",
    "describe(a[, axis, ddof, bias, nan_policy]) \n",
    "gmean(a[, axis, dtype]) \n",
    "hmean(a[, axis, dtype]) \n",
    "skew(a[, axis, bias, nan_policy]) # of ds or col ?\n",
    "kurtosis(a[, axis, fisher, bias, nan_policy]) # of ds or col ? (Fisher or Pearson)\n",
    "mode(a[, axis, nan_policy]) # array of most common value from passed array\n",
    "moment(a[, moment, axis, nan_policy]) # nth moment about the mean for a sample.\n",
    "variation(a[, axis, nan_policy]) # CHECK IT # variance coeff (std against mean).\n",
    "\n",
    "# - Trimmed desctiptive statistics:\n",
    "tmean(a[, limits, inclusive, axis]) \n",
    "tvar(a[, limits, inclusive, axis, ddof]) \n",
    "tmin(a[, lowerlimit, axis, inclusive, …]) \n",
    "tmax(a[, upperlimit, axis, inclusive, …]) \n",
    "tstd(a[, limits, inclusive, axis, ddof]) \n",
    "tsem(a[, limits, inclusive, axis, ddof]) \n",
    "\n",
    "# - Distribution tests to check if\n",
    "normaltest(a[, axis, nan_policy])   # - sample dist is normal,\n",
    "skewtest(a[, axis, nan_policy])     # - is ds skew normal,\n",
    "kurtosistest(a[, axis, nan_policy]) # - ds kurt is normal.\n",
    "\n",
    "# Others\n",
    "find_repeats(arr) # Find repeats and repeat counts.\n",
    "trim_mean(a, proportiontocut[, axis]) # Return mean of array after trimming distribution from both tails.\n",
    "\n",
    "# - K stat\n",
    "kstat(data[, n]) # nth k-statistic (1<=n<=4 so far).\n",
    "kstatvar(data[, n]) # unbiased estimator of the variance of the k-statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 2\n",
    "\n",
    "\n",
    "\n",
    "# Return a cumulative frequency histogram, using the histogram function.\n",
    "cumfreq(a[, numbins, defaultreallimits, weights])\n",
    "# itemfreq is deprecated! itemfreq is deprecated and will be removed in a future version.\n",
    "itemfreq(*args, **kwds)\n",
    "# The percentile rank of a score relative to a list of scores.\n",
    "percentileofscore(a, score[, kind])\n",
    "# Calculate the score at a given percentile of the input sequence.\n",
    "scoreatpercentile(a, per[, limit, …])\n",
    "# Return a relative frequency histogram, using the histogram function.\n",
    "relfreq(a[, numbins, defaultreallimits, weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 3\n",
    "\n",
    "\n",
    "\n",
    "# Compute a binned statistic for one or more sets of data.\n",
    "binned_statistic(x, values[, statistic, …]) \n",
    "# Compute a bidimensional binned statistic for one or more sets of data.\n",
    "binned_statistic_2d(x, y, values[, …]) \n",
    "# Compute a multidimensional binned statistic for a set of data.\n",
    "binned_statistic_dd(sample, values[, …]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 4\n",
    "\n",
    "\n",
    "\n",
    "# Compute the O’Brien transform on input data (any number of arrays).\n",
    "obrientransform(*args)\n",
    "# Bayesian confidence intervals for the mean, var, and std.\n",
    "bayes_mvs(data[, alpha])\n",
    "# ‘Frozen’ distributions for mean, variance, and standard deviation of data.\n",
    "mvsdist(data)\n",
    "# Calculate the standard error of the mean (or standard error of measurement) of the values in the input array.\n",
    "sem(a[, axis, ddof, nan_policy])\n",
    "# Calculate the relative z-scores.\n",
    "zmap(scores, compare[, axis, ddof])\n",
    "# Calculate the z score of each value in the sample, relative to the sample mean and standard deviation.\n",
    "zscore(a[, axis, ddof])\n",
    "# Compute the interquartile range of the data along the specified axis\n",
    "iqr(x[, axis, rng, scale, nan_policy, …])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 5\n",
    "\n",
    "\n",
    "\n",
    "# Iterative sigma-clipping of array elements.\n",
    "sigmaclip(a[, low, high]) \n",
    "# Slices off a proportion of items from both ends of an array.\n",
    "trimboth(a, proportiontocut[, axis]) \n",
    "# Slices off a proportion from ONE end of the passed array distribution.\n",
    "trim1(a, proportiontocut[, tail, axis]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 6\n",
    "\n",
    "\n",
    "\n",
    "# Performs a 1-way ANOVA.\n",
    "f_oneway(*args)\n",
    "# Calculate a Pearson correlation coefficient and the p-value for testing non-correlation.\n",
    "pearsonr(x, y)\n",
    "# Calculate a Spearman rank-order correlation coefficient and the p-value to test for non-correlation.\n",
    "spearmanr(a[, b, axis, nan_policy])\n",
    "# Calculate a point biserial correlation coefficient and its p-value.\n",
    "pointbiserialr(x, y)\n",
    "# Calculate Kendall’s tau, a correlation measure for ordinal data.\n",
    "kendalltau(x, y[, initial_lexsort, nan_policy])\n",
    "# Compute a weighted version of Kendall’s .\n",
    "weightedtau(x, y[, rank, weigher, additive])\n",
    "# Calculate a linear least-squares regression for two sets of measurements.\n",
    "linregress(x[, y])\n",
    "# Computes the Theil-Sen estimator for a set of points (x, y).\n",
    "theilslopes(y[, x, alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 6\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the T-test for the mean of ONE group of scores.\n",
    "ttest_1samp(a, popmean[, axis, nan_policy])\n",
    "# Calculate the T-test for the means of two independent samples of scores.\n",
    "ttest_ind(a, b[, axis, equal_var, nan_policy])\n",
    "# T-test for means of two independent samples from descriptive statistics.\n",
    "ttest_ind_from_stats(mean1, std1, nobs1, …)\n",
    "# Calculate the T-test on TWO RELATED samples of scores, a and b.\n",
    "ttest_rel(a, b[, axis, nan_policy])\n",
    "# Perform the Kolmogorov-Smirnov test for goodness of fit.\n",
    "kstest(rvs, cdf[, args, N, alternative, mode])\n",
    "# Calculate a one-way chi square test.\n",
    "chisquare(f_obs[, f_exp, ddof, axis])\n",
    "# Cressie-Read power divergence statistic and goodness of fit test.\n",
    "power_divergence(f_obs[, f_exp, ddof, axis, …])\n",
    "# Compute the Kolmogorov-Smirnov statistic on 2 samples.\n",
    "ks_2samp(data1, data2)\n",
    "# Compute the Mann-Whitney rank test on samples x and y.\n",
    "mannwhitneyu(x, y[, use_continuity, alternative])\n",
    "# Tie correction factor for ties in the Mann-Whitney U and Kruskal-Wallis H tests.\n",
    "tiecorrect(rankvals)\n",
    "# Assign ranks to data, dealing with ties appropriately.\n",
    "rankdata(a[, method])\n",
    "# Compute the Wilcoxon rank-sum statistic for two samples.\n",
    "ranksums(x, y)\n",
    "# Calculate the Wilcoxon signed-rank test.\n",
    "wilcoxon(x[, y, zero_method, correction])\n",
    "# Compute the Kruskal-Wallis H-test for independent samples\n",
    "kruskal(*args, **kwargs)\n",
    "# Compute the Friedman test for repeated measurements\n",
    "friedmanchisquare(*args)\n",
    "# Methods for combining the p-values of independent tests bearing upon the same hypothesis.\n",
    "combine_pvalues(pvalues[, method, weights])\n",
    "# Perform the Jarque-Bera goodness of fit test on sample data.\n",
    "jarque_bera(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 8\n",
    "\n",
    "# Perform the Ansari-Bradley test for equal scale parameters\n",
    "ansari(x, y)\n",
    "# Perform Bartlett’s test for equal variances\n",
    "bartlett(*args)\n",
    "# Perform Levene test for equal variances.\n",
    "levene(*args, **kwds)\n",
    "# Perform the Shapiro-Wilk test for normality.\n",
    "shapiro(x)\n",
    "# Anderson-Darling test for data coming from a particular distribution\n",
    "anderson(x[, dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 9\n",
    "\n",
    "\n",
    "\n",
    "# The Anderson-Darling test for k-samples.\n",
    "anderson_ksamp(samples[, midrank])\n",
    "# Perform a test that the probability of success is p.\n",
    "binom_test(x[, n, p, alternative])\n",
    "# Perform Fligner-Killeen test for equality of variance.\n",
    "fligner(*args, **kwds)\n",
    "# Mood’s median test.\n",
    "median_test(*args, **kwds)\n",
    "# Perform Mood’s test for equal scale parameters.\n",
    "mood(x, y[, axis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 10\n",
    "\n",
    "\n",
    "\n",
    "# Return a positive dataset transformed by a Box-Cox power transformation.\n",
    "boxcox(x[, lmbda, alpha])\n",
    "# Compute optimal Box-Cox transform parameter for input data.\n",
    "boxcox_normmax(x[, brack, method])\n",
    "# The boxcox log-likelihood function.\n",
    "boxcox_llf(lmb, data)\n",
    "# Calculate the entropy of a distribution for given probability values.\n",
    "entropy(pk[, qk, base])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 11\n",
    "\n",
    "\n",
    "\n",
    "# Compute the first Wasserstein distance between two 1D distributions.\n",
    "wasserstein_distance(u_values, v_values[, …])\n",
    "# Compute the energy distance between two 1D distributions.\n",
    "energy_distance(u_values, v_values[, …])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# Circular statistical functions\n",
    "# ------------------------------\n",
    "# Compute the circular mean for samples in a range.\n",
    "circmean(samples[, high, low, axis])\n",
    "# Compute the circular variance for samples assumed to be in a range\n",
    "circvar(samples[, high, low, axis])\n",
    "# Compute the circular standard deviation for samples assumed to be in the range [low to high].\n",
    "circstd(samples[, high, low, axis])\n",
    "\n",
    "\n",
    "# Contingency table functions\n",
    "# ---------------------------\n",
    "# Chi-square test of independence of variables in a contingency table.\n",
    "chi2_contingency(observed[, correction, lambda_])\n",
    "# Compute the expected frequencies from a contingency table.\n",
    "contingency.expected_freq(observed)\n",
    "# Return a list of the marginal sums of the array a.\n",
    "contingency.margins(a)\n",
    "# Performs a Fisher exact test on a 2x2 contingency table.\n",
    "fisher_exact(table[, alternative])\n",
    "\n",
    "\n",
    "# Plot-tests\n",
    "# ----------\n",
    "# Calculate the shape parameter that maximizes the PPCC\n",
    "ppcc_max(x[, brack, dist])\n",
    "# Calculate and optionally plot probability plot correlation coefficient.\n",
    "ppcc_plot(x, a, b[, dist, plot, N])\n",
    "# Calculate quantiles for a probability plot, and optionally show the plot.\n",
    "probplot(x[, sparams, dist, fit, plot, rvalue])\n",
    "# Compute parameters for a Box-Cox normality plot, optionally show it.\n",
    "boxcox_normplot(x, la, lb[, plot, N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
